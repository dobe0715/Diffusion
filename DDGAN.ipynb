{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhNift5JIi6Z4F9fpOZAS0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tackling The Generative learning Trilemma with Denoising Diffusion GANs"],"metadata":{"id":"yb5qMHyy4t3O"}},{"cell_type":"markdown","source":["## Contributions"],"metadata":{"id":"wAmZFZzW4t1Q"}},{"cell_type":"markdown","source":["+ 생성모델의 큰 문제인 퀄리티, 다양성, 속도 세가지 단점을 diffusion model과 GAN을 결합하여 해결하였다.\n"],"metadata":{"id":"EnGWq89S4tzb"}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{"id":"M6f7Utd64txE"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1PhLm3Quz8ujgGS8Wycjjm0RyYO6z4LbP\" height=300>"],"metadata":{"id":"Jblrvh404tut"}},{"cell_type":"markdown","source":["+ 생성모델의 3가지  문제\n","    + high quality sampling\n","    + mode coverage & sample diversity\n","    + sampling speed & computational cost"],"metadata":{"id":"PJ11kPu84tsk"}},{"cell_type":"markdown","source":["GAN, VAE, normalizaint flow, diffusion 등의 여러 모델이 나왔지만, 모든 부분에서 우수한 모델은 없었다."],"metadata":{"id":"EZUYotjc4tp2"}},{"cell_type":"markdown","source":["denoising diffusion 모델에 tackle을 걸 것이다!"],"metadata":{"id":"-nFNdRtn4tnz"}},{"cell_type":"markdown","source":["__diffusion process의 reverse 과정을 Gaussian distribution으로 가정하기 때문에 극히 작은 step의 denoising을 할 수 있다__"],"metadata":{"id":"xZ4OSH9R4tls"}},{"cell_type":"markdown","source":["image synthesis 분야에서 multimodal distribution이 자연스럽다."],"metadata":{"id":"9hEympOw4tjK"}},{"cell_type":"markdown","source":["## Denoising Diffusion GANs"],"metadata":{"id":"HC71vIPh4tg4"}},{"cell_type":"markdown","source":["forward process(가정)\n","+ $q(x_t|x_{t-1}) = \\mathcal{N}(x_t;\\sqrt{1-\\beta_t}x_{t-1}, \\beta_t\\mathbf{I})$  \n"],"metadata":{"id":"ITi3Ysa0slUT"}},{"cell_type":"markdown","source":["reverse process(근사)  \n","+ $p_{\\theta}(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1};\\mu_\\theta(x_t, t), \\sigma^2_t\\mathbf{I})$"],"metadata":{"id":"44MhP5oktDBM"}},{"cell_type":"markdown","source":["### Multimodal denoising distributions for large denoising steps"],"metadata":{"id":"bzDuopIz4teU"}},{"cell_type":"markdown","source":["+ multimodal distribution : 여러개의 최빈값을 갖는 분포"],"metadata":{"id":"f1tJvqX84tZy"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1hYak1uhu0tBLDjP1NKC9qehncEMSY071\" height=250>"],"metadata":{"id":"2er-JEK14tcc"}},{"cell_type":"markdown","source":["diffusion model은 결국 $q(x_{t-1}|x_t)$를 Gaussian distribution으로 가정하고, 이를 파라미터화 하여 근사해나가는 과정이다."],"metadata":{"id":"44PJsDOF4tXO"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=16o31ZKwJZXt_rMvMAQqD5GhfFg00oMSP\" height=300>"],"metadata":{"id":"Uew4usNS4tUz"}},{"cell_type":"markdown","source":["#### why single denoising process is Gaussian?\n","1. 만약 variance $\\beta_t$가 아주 작다면, 베이즈정리 에서 $q(x_t|x_{t-1})$값이 지배적이게 된다고 한다. (why?) 또한 forward는 Gaussian을 가정하였으므로 $q(x_{t-1}|x_t)$역시 Gaussian이라고 한다."],"metadata":{"id":"QNatAXCt4tRM"}},{"cell_type":"markdown","source":["2. denoising 과정에서 $q(x_t)$ 분포 자체가 Gaussian이라면 $q(x_{t-1}|x_t)$가 Gaussian 이 성립한다. 이러한 방법은 VAE encoder를 이용하는 방법 등이 있지만, 그리 완벽한 성능을 보이고있지 않다."],"metadata":{"id":"A2hVJhX44tMa"}},{"cell_type":"markdown","source":["기존의 diffusion model들은 이러한 가정하에 approximation을 진행하고 있고, 그것이 옳다.  \n"," __다만, 작은 $\\beta$를가진 수천번의 step이 필요해진다.__"],"metadata":{"id":"bcuwivyo4tO1"}},{"cell_type":"markdown","source":["__해당 논문에선 denosing step을 키우고(보폭을 키운다는 뜻), denoising data distribution을 non-Gaussian으로 가정한다.(Fig.2)__"],"metadata":{"id":"XZH0vQ8K4tJz"}},{"cell_type":"markdown","source":["### Modeling distribution with conditional GANs"],"metadata":{"id":"rc4vJYiz4tHr"}},{"cell_type":"markdown","source":["기존과 다른점은, $T \\leq 8$으로 매우 작은 step이다.    \n","conditional GAN generator를 $p_\\theta(x_{t-1}|x_t)$와 같이 정의하였을 때\n","목적함수는 다음과 같다.  \n","$$\\min_\\theta \\sum_{t \\geq 1}\\mathbb{E}_{q(x_t)}[D_{adv}(q(x_{t-1}|x_t)||p_\\theta(x_{t-1}|x_t))]$$"],"metadata":{"id":"-yNm_I0TOHFD"}},{"cell_type":"markdown","source":["$D_{adv}$로 여러가지 거리공간을 사용한다. 여기선 f-divergence를 사용하였다.(backward KL divergence)"],"metadata":{"id":"BScI6WImOHCk"}},{"cell_type":"markdown","source":["$D_\\phi$ : Discriminator  \n","$G_\\theta$ : Generator"],"metadata":{"id":"qui1edzPOHAZ"}},{"cell_type":"markdown","source":["#### Training Discriminator\n","$D_\\phi(x_{t-1}, x_t, t) : \\mathbb{R}^N \\times \\mathbb{R}^N \\times \\mathbb{R} \\rightarrow [0, 1]$"],"metadata":{"id":"rx1HzR9tOG8_"}},{"cell_type":"markdown","source":["+ objective function\n","$$\\min_\\phi \\sum_{t \\leq1}\\mathbb{E}_{q(x_t)} \\big[\\mathbb{E}_{q(x_{t-1}|x_t)}[-\\log(D_\\phi(x_{t-1}, x_t, t))] + \\mathbb{E}_{p_\\theta(x_{t-1}|x_t)}[-\\log(1 - D_\\phi(x_{t-1}, x_t, t))] \\big]$$"],"metadata":{"id":"K9Q121TrOG6G"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=167i18h7wBn9eJt79eAVnfwk1JxrtT68j\" height=500>"],"metadata":{"id":"Izl4pNQxOG4G"}},{"cell_type":"markdown","source":["즉, $x_0$로 $x_{t-1}$을 뽑고 그것으로 $x_t$를 샘플링해주면 된다.  \n","(이렇게 하는 이유는 true reverse process를 아직 정의해놓지 않았기 때문이다.)"],"metadata":{"id":"bcyxN4YkOG1_"}},{"cell_type":"markdown","source":["#### Parametrizing the implicit denoising model  \n","GAN 장점이자 단점이 바로 분포를 모르는 상태로 모델링한다는 것이다."],"metadata":{"id":"BIgBkFTgOGyB"}},{"cell_type":"markdown","source":["+ 기존의 denoising 방식(DDPM)  \n","$p_\\theta(x_{t-1}|x_t) := q(x_{t-1}|x_t, x_0 = f_\\theta(x_t, t))$  \n","1. $x_t$를 모델에 넣어 해당 time step의 noise인 $\\epsilon_\\theta(x_t)$을 얻어낸다.\n","2. 여기에 사전에 정의한 $\\alpha$와 $x_t, \\epsilon_\\theta(x_t)$를 이용해  $x_0$를 얻어낸다.\n","3. $x_t, x_0$ 두개를 통해 Gaussian distribution의 mean, variance 얻어내고 여기에서 $x_{t-1}$을 샘플링 해낸다."],"metadata":{"id":"HAEdSpmlOGu-"}},{"cell_type":"markdown","source":["+ 본 논문 denoising 방식(DDGAN)  \n","$p_\\theta(x_{t-1}|x_t) := \\int p_\\theta(x_0|x_t)q(x_{t-1}|x_t, x_0)dx_0 = \\int p(z)q(x_{t-1}|x_t, x_0 = G_\\theta(x_t, z, t))dz$  \n","1. random noise $z$를 얻어낸다. $\\mathcal{N}(z;0, \\mathbf{I})$\n","2. $x_t$와 $z$를 GAN에 넣어 $x_0$을 얻어낸다.\n","3. $x_t, x_0$ 두개를 통해 Gaussian distribution의 mean, variance 얻어내고 여기에서 $x_{t-1}$을 샘플링 해낸다."],"metadata":{"id":"Gf-P4Y0sOGsY"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1VhP_7Z5Xtw4hqgqIqv3GvvA6p1GZzmJy\" height=300>"],"metadata":{"id":"h4Qk5Lq0OGqO"}},{"cell_type":"markdown","source":["#### Advantage over DDPM\n","1. $p_\\theta$를 DDPM과 비슷한 형태로 parameter화 하였다.\n","    + 비슷한 inductive bias를 가져갈 수 있다.\n","2. 각 time step에 $x_0$만 예측할 수 있으면 된다. (문제 정의가 더 쉬워진다.)\n","    + 기존에는 t-1 -> t에 해당하는 1step noise를 예측해내야 했으나, 해당 모델은 t step 전체를 예측하게 됨."],"metadata":{"id":"pPa-gYB_OGk7"}},{"cell_type":"markdown","source":["__$x_0$를 얻어낼 때 GAN을 사용하는 것이 DDPM(U-Net)과의 가장 큰 차이점이고, 이를 통해 $p_\\theta(x_{t-1}|x_t)$가 multimodal distribution이 되는 열쇠이다.__"],"metadata":{"id":"6LfSWcElOGnO"}},{"cell_type":"markdown","source":["$x_t \\rightarrow x_0$에서\n","+ DDPM : deterministic (by only $\\alpha$)\n","    + unimodal (Gaussian)\n","+ DDGAN : random (by $z$)\n","    + multimodal (GAN이기 때문에 분포는 모르지만, true denoising distribution을 따라서 sampling되게 된다. (Implicit))"],"metadata":{"id":"3z70o-D34tA6"}},{"cell_type":"markdown","source":["#### Advantage over one-shot generator(GAN)"],"metadata":{"id":"DKecCJMgApFY"}},{"cell_type":"markdown","source":["기존 GAN의 어려움\n","+ training instability,  mode collapse\n","+ 특정 clean sample들만 볼 때 Discriminator가 overfitting되기도한다.\n","+ 복잡한 분포로부터 바로 sampling 하는 것의 어려움."],"metadata":{"id":"DT1KmCcEApCu"}},{"cell_type":"markdown","source":["장점  \n","1. 각 step마다 상대적으로 간단한 모델로 예측할 수 있게된다.  \n","$\\because x_t$ is strong condition\n","2. Discriminator가 overfit될 가능성을 낮췄다.  \n","$\\because$ diffusion process가 data의 분포를 smooth하게 해준다. -> less clean"],"metadata":{"id":"aHNeo6j7Ao_n"}},{"cell_type":"markdown","source":["## Experiments"],"metadata":{"id":"7JS9YhBgAo8x"}},{"cell_type":"markdown","source":["T=4일 때 가장 좋았고 이것을 기준으로 다른 모델들과 비교하였다."],"metadata":{"id":"g8Bz2eGdGLFp"}},{"cell_type":"markdown","source":["### Overcoming the Generative learning Trilemma"],"metadata":{"id":"b1PFW4g0DY8r"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1kD1hNqKMgcGfZiytDe7YCaHwFPsBER7J\" height=300>"],"metadata":{"id":"hi0pif6FDY43"}},{"cell_type":"markdown","source":["trade-off를 상당히 해결하였음을 볼 수 있다."],"metadata":{"id":"6qeLCDDfGTzm"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1lf8dkxumm3feavbjqf6rIW_hEwMhV-K_\" width=500>"],"metadata":{"id":"K6-9-21KDY1T"}},{"cell_type":"markdown","source":["sample diversity에 해당하는 recall score가 style gan보다 좋다.\n","(실제 데이터셋을 더욱 많이 cover한다.)"],"metadata":{"id":"loUSZo1NDYyO"}},{"cell_type":"markdown","source":["### Ablation studies"],"metadata":{"id":"i41JBW25DYul"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1-wJnuCbqnuspMj2XKWXRkHfOPxA_2SY_\" height=250>"],"metadata":{"id":"-Qpvth2QDYrw"}},{"cell_type":"markdown","source":["+ Number of denoising steps\n","    + T = 1 -> unconditional GAN\n","    + T = 4 : best model\n","+ Diffusion as data augmentation\n","    + forward process를 살펴보면, 원래 데이터에 noise가 들어간 것이 augmentation이라고 볼 수 있다. 이러한 데이터를 그냥 GAN에 적용하여 학습시켜봤다.\n","    + 결과 안좋음. -> DDGAN과 GAN은 다르다.\n","+ Parametrization for $p_\\theta(x_{t-1}|x_t)$\n","    + direct denoising ($x_t \\rightarrow x_{t-1}$\n","    + noise generation\n","+ Importance of latent variable\n","    + z를 제거해보았다. -> 안좋음\n","    + multimodal denoising distribution의 중요성!"],"metadata":{"id":"KwNfZWJDDYoS"}},{"cell_type":"markdown","source":["### Additional studies"],"metadata":{"id":"ms8N1fyWDYjl"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1JTIFWmaQQxYTcvn8bjvDuZ1w7H9JH22J\" height=200>"],"metadata":{"id":"3PigKVt8Ao3r"}},{"cell_type":"markdown","source":["우수한 Mode coverage를 가지고 있다."],"metadata":{"id":"7s2f3jOXNjwf"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1rOPbUwkkOBv4bkzl3dn1StlPVp6oXaKb\" height=150>"],"metadata":{"id":"mAuF8frjAo0D"}},{"cell_type":"markdown","source":["sample quality역시 우수하다."],"metadata":{"id":"ABFxSVSVAovt"}}]}