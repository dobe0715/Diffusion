{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOuRmkieaMb0WwuL8HpN/VF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# High-Resolution Image Synthesis with Latent Diffusion Models(Stable Diffusion)"],"metadata":{"id":"IgnsdOW4JxRR"}},{"cell_type":"markdown","source":["참고자료\n","+ paper : https://arxiv.org/abs/2112.10752\n","+ youtube : https://www.youtube.com/watch?v=rC34475rEnw\n","+ blog : https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/ldm/  \n","\n","\n"],"metadata":{"id":"qV6vv3GiJyoW"}},{"cell_type":"markdown","source":["## Contributions\n","1. 기존의 DM들에 비해 소모되는 컴퓨팅 자원을 훨씬 줄였다. => 탄소배출 감소..^^\n","2. space에 따라 2-stage로 나눠 학습으로써 더욱 효율적인 모델을 찾을 수 있었다.\n","3. cross-attention을 U-Net에 적용하여 다양한 class condition을 줄 수 있다.\n","4. 사전학습모델을 무료공개했다."],"metadata":{"id":"gq3ExboWJymb"}},{"cell_type":"markdown","source":["## 기존의 이미지 생성모델들"],"metadata":{"id":"6NOAFwSEJyj3"}},{"cell_type":"markdown","source":["+ GAN\n","    + 장점 : 좋은 퀄리티의 고해상도 이미지\n","    + 단점 : 데이터 분포 전체 학습에서의 어려움(mode collapse 위험)\n","\n","+ VAE(Likelihood-based)\n","    + 장점 : 데이터 분포 학습이 잘됨\n","    + 단점 : 셈플 퀄리티 GAN에 비해 상대적 낮음\n","\n","+ ARM(Auto Regressive Model, pixel RNN,CNN 등)\n","    + 장점 : 데이터 분포 학습이 잘됨\n","    + 단점 : sequential 하게 sampling하기 위해 해상도의 한계, 컴퓨팅 요구량\n","\n","<img src=\"https://drive.google.com/uc?id=1DdFVj2w-wq8CKrONIGxEJvf91dWvvBDL\" height=300>\n","\n","+ DM(Diffusion Probablistic Model)\n","    + 장점 : 분포학습 + 퀄리티 + inductive bias\n","    + 단점 : inference 및 training에서의 cost\n","\n","+ 2-stage ARM(VQ-VAE, VQ-GAN 등)\n","    + 장점 : 기존의 해상도 한계를 quantization을 통해 극복\n","    + 단점 : 모델 표현력을 끌어올리는데 한계가 있다.(compression rate를 높이면, 결국 학습할 파라미터 수가 너무 많아짐)\n","\n","<img src=\"https://drive.google.com/uc?id=11VlpjQDLlJakEKBBikgk5IcBHLQkoWKg\" height=350>"],"metadata":{"id":"9bdVHkyaJyiH"}},{"cell_type":"markdown","source":["LDM(Latent Diffusion Model)은, 결국 위의 마지막 두가지를 결합한 모델이다."],"metadata":{"id":"0VmHOFiPJyfy"}},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"7_k2jP-YJydU"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=130yyc3D_P9OCcMu4YEtCBWM1w6w2v3Bt\" height=300>"],"metadata":{"id":"V0VOkIbHJyao"}},{"cell_type":"markdown","source":["두개의 stage로 나뉜다.\n","1. 이미지 압축 (encoder/decoder)\n","2. diffusion process"],"metadata":{"id":"hXEZkjyrJyYN"}},{"cell_type":"markdown","source":["### Perceptual Image Compression\n","주어진 이미지 x 를 latent space로 mapping해주는 단계이다. pixel 단계에서의 detail한 부분을 날려 압축해주어 계산복잡도를 낮춘다.\n"],"metadata":{"id":"EHKFXiriJyWD"}},{"cell_type":"markdown","source":["+ encoder : $z = \\mathcal{E}(x)$\n","+ decoder : $\\tilde{x} = \\mathcal{D}(z)$\n","+ $x$ : $H \\times W \\times 3$, RGB 이미지\n","+ $z$ : $h \\times w \\times c$, latent\n","+ $f = H/h = W/w$ : downsampling factor. 이 값을 기준으로 LDM 모델 나눔. $f \\in \\{1, 2, 4, ..., 32\\}$"],"metadata":{"id":"l8J4VagsJyTp"}},{"cell_type":"markdown","source":["이 때, encoder, decoder를 학습할 때 latent space의 variance를 균등하게 하기 위해서 두가지 regularization loss를 추가한다.  "],"metadata":{"id":"SZbfMQmZJySW"}},{"cell_type":"markdown","source":["+ KL-reg : normal distribution과의 KL divergence계산\n","+ VQ-reg : VQGAN loss와 비슷한 역할.  "],"metadata":{"id":"wK5GHZWZJyQX"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1Hp1e3mDsHbQwumhIJEkBW15_ryMGODgY\" width=800>"],"metadata":{"id":"DQqaDjoxJyM7"}},{"cell_type":"markdown","source":["### Latent Diffusion Model\n","$L_{LDM} := \\mathbb{E}_{\\mathcal{E}(x), \\epsilon \\sim N(0, 1), t}\\bigg[||\\epsilon - \\epsilon_\\theta(z_t, t)||_2^2\\bigg]$\n","\n","UNet기반 backbone을 사용한다."],"metadata":{"id":"0ZfiP9ioJyKo"}},{"cell_type":"markdown","source":["### Conditioning Mechanisms\n","기존의 condition을 줄때에는 단순히 y를 label값으로만 줄 수 있었다. 하지만, 여기서는 Cross-Attention을 이용하여text, resolution, semantic map 등을 domain encoder $\\tau_\\theta$를 이용하여 embedding해서 UNet에 넣어준다."],"metadata":{"id":"qznQirhsumHg"}},{"cell_type":"markdown","source":["$Q = W_Q^{(i)} \\cdot \\phi_i(z_i), K = W_K^{(i)} \\cdot \\tau_\\theta(y), V = W_V^{(i)} \\cdot \\tau_\\theta(y)$"],"metadata":{"id":"zCQQdybfumFJ"}},{"cell_type":"markdown","source":["최종적으로 LDM loss는 다음과 같다.  \n","$L_{LDM} := \\mathbb{E}_{\\mathcal{E}(x), y, \\epsilon \\sim N(0, 1), t}\\bigg[||\\epsilon - \\epsilon_\\theta(z_t, t, \\tau_\\theta(y))||_2^2\\bigg]$"],"metadata":{"id":"z5qqPZ5uumCd"}},{"cell_type":"markdown","source":["이 때, $\\tau_\\theta, \\epsilon_\\theta$는 동시에 optimize된다. 그리고, condition domain에 따라 $\\tau_\\theta$를 다양하게 파라미터화 할 수 있다."],"metadata":{"id":"2-XW71EvulpS"}},{"cell_type":"markdown","source":["## Experiments"],"metadata":{"id":"570t0o-xJxO2"}},{"cell_type":"markdown","source":["### On Perceptual Compression Tradeoffs\n","\n","downsampling factor $f \\in \\{1, 2, 4, 8, 16, 32\\}$에 따라 $LDM-f$라고 부른다. 또한, $LDM-1$은 기존의 pixel based DM에 대응된다.\n","\n","<img src=\"https://drive.google.com/uc?id=137vp-lW-ICBT2mEuN5HfHNGJ1hbdCwAc\" height=300>"],"metadata":{"id":"egGX7E6M_xUT"}},{"cell_type":"markdown","source":["살펴보면, f=1,2,32일 때 성능이 좋지 않음을 알 수 있다.\n","즉, tradeoff에 대한 적당한 optimal point가 있다는 뜻"],"metadata":{"id":"87lTxpS-_xQY"}},{"cell_type":"markdown","source":["### Image Generation with LDM"],"metadata":{"id":"b9UW8UxN_xOp"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1gKJ3dIrbm74nDHRy_G-QSDGZK-wqOAkx\" height=400>  \n","기존 생성모델들의 성능을 거의 다 뛰어넘었다."],"metadata":{"id":"nSeIQbwO_xL6"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1O9Zsjum0gdZasLMGvYz54Mx0WabEVN9z\" height=200>  \n","condition guaidance를 줬을 땐, FID점수도 많이 올릴 수 있다."],"metadata":{"id":"fVok2xyV_xJj"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1DkkPHLAcCaG_RJTUBP1zmzkBIEAu9Fyx\" height=150>  \n","Super Resolution, Inpainting 분야에서도 좋은 성능을 보인다."],"metadata":{"id":"QINmara7_xGB"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1N5fOTht4zWHiVCcVI0Od5efviGlnboxv\" width=500>"],"metadata":{"id":"zL8JWh9XJxHy"}},{"cell_type":"markdown","source":["## Limitation\n","computation 요구량을 확실히 줄였지만, 아직은 GAN에 비하면 턱없이 느리다.  \n","또한, $f = 4$에서 좋은 퀄리티를 보였지만, pixel space에서 정확도를 얻기 위해서는 bottleneck이 될 수 있다."],"metadata":{"id":"S_jpX6lWFAV1"}},{"cell_type":"code","source":[],"metadata":{"id":"Gr4ovANgV-nn"},"execution_count":null,"outputs":[]}]}