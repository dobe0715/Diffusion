{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSTFNqg3v9W3VgPa4t1KuL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Scalable Diffusion Models with Transformers"],"metadata":{"id":"m4EqHtx8KaHX"}},{"cell_type":"markdown","source":["참고링크\n","+ https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/dit/"],"metadata":{"id":"chGM0MqMKaFL"}},{"cell_type":"markdown","source":["## Contributions\n","+ 기존의 U-Net backbone을 Transformer로 변경하였다.\n","+ 모델을 scaling하며 sample quality와 Gflops간의 상관 관계를 연구하였다.\n","+ SOTA 달성하였다"],"metadata":{"id":"fJ4pt8lBKaDP"}},{"cell_type":"markdown","source":["__추가로, 요즘 Sora, stable diffusion v3 와 같은 최신모델들이 Diffusion transformer를 사용하고 있다.__"],"metadata":{"id":"l0Xl3zjJNYb6"}},{"cell_type":"markdown","source":["## 1. Introduction\n"],"metadata":{"id":"35g33dpSKaBV"}},{"cell_type":"markdown","source":["+ 지금은 Transformer의 르네상스 시대를 맞고있다.\n","    + 그런데 DDPM의 백본으로 사용하는 U-Net을 보면 CNN기반에 self-attention추가한 정도이다.\n","    + 거기에서 구조의 변경도 크게 없다.\n","\n","+ 우리는 백본으로 Transformer 모델을 사용해보았다.\n","    + 우리는 생성모델에 있어서 U-Net의 inductive bias가 의미가 없는 것을 보였다.(CNN vs ViT에서의 논쟁)\n","    + 이러한 구조의 모델을 DiT라고 부르겠다.\n","    + 이 모델의 scaling을 통해 모델 complexity(Gflops) vs 샘플 quality의 trade off를 연구하였다."],"metadata":{"id":"U8ERPBUwKZ-y"}},{"cell_type":"markdown","source":["## 2. Preliminaries"],"metadata":{"id":"Uq9DDtKxKZ6J"}},{"cell_type":"markdown","source":["### Diffusion formulation"],"metadata":{"id":"faBofolaKZ8Y"}},{"cell_type":"markdown","source":["+ forward process  \n","미리 hyper parameter로 scheduling되어있는 variance값 $\\alpha$로부터 sampling할 수 있다. (by reparameterization trick)  \n","\n"," $x_0 : q(x_t|x_T) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t}x_0, (1-{\\bar{\\alpha}_t})\\mathbf{I})$"],"metadata":{"id":"sHbsQER6KZ3K"}},{"cell_type":"markdown","source":["+ reverse process  \n","neural net $\\theta$를 통해 forward process의 역과정을 예측한다.  \n","$p_\\theta (x_{t-1}|x_t) = \\mathcal{N}(\\mu_\\theta(x_t), \\Sigma_\\theta(x_t))$"],"metadata":{"id":"hAlk6_ZZKZ03"}},{"cell_type":"markdown","source":["+ loss function  \n","Variational lower bound를 최대화하는 방향으로 학습한다.  \n","$\\mathcal{L}(\\theta) = -p(x_0|x_1) + \\sum_t{\\mathcal{D}_{KL}(q^*(x_{t-1}|x_t, x_0)||p_\\theta(x_{t-1}|x_t))}$  \n","    + 이 때, $\\mu_\\theta$ 대신 $\\epsilon_\\theta$를 출력하는 모델을 이용해 학습시킨다.\n","    + $\\epsilon_\\theta$는 $\\mathcal{L}_{simple}$을 학습시키고 $\\Sigma_\\theta$는 $\\mathcal{L}$전체를 학습시킨다. (Improved ddpm paper)"],"metadata":{"id":"4ShgUmNYKZy9"}},{"cell_type":"markdown","source":["### Classifier-free guidance"],"metadata":{"id":"cFFt4q6jKZv0"}},{"cell_type":"markdown","source":["+ Classifier guidance(Diffusion models beats GANs paper)  \n","Condition diffusion 모델은 결국 sampling에서  \n","$\\log p(c|x)$를 최대화하는 x를 찾는 것이다.  \n","그러한 모델 $p_\\phi(c|x)$를 정의한다."],"metadata":{"id":"jFEjsgGTWR-i"}},{"cell_type":"markdown","source":["+ Classifier-free guidance  \n","기존 conditional loss의 $\\log p(c|x)$ 텀을 베이지안 룰을 통해 잘 변경하였더니, 따로 모델을 사용할 필요가 없어졌다.  \n","$\\hat{\\epsilon_\\theta}(x_t, c) = \\epsilon_\\theta(x_t, \\emptyset) + s \\cdot (\\epsilon_\\theta(x_t, c) - \\epsilon_\\theta(x_t, \\emptyset))$  \n","    + $c = \\emptyset$ -> \"null\" embedding\n","    + s : cfg hyper parameter"],"metadata":{"id":"QcM16ocsWR8X"}},{"cell_type":"markdown","source":["### Latent diffusion models"],"metadata":{"id":"NH9AwHMSWR50"}},{"cell_type":"markdown","source":["기존의 DDPM process를 2-stage로 나누었다.\n","+ learnning autoencoder with compressed images representations $E(\\cdot)$\n","+ encoder는 고정시켜놓고 $z = E(x)$를 diffusion model에 학습시킨다. 그리고 decoder를 학습한다. $x = D(z)$"],"metadata":{"id":"aTEqTL1WWR3j"}},{"cell_type":"markdown","source":["__본 논문에서는 classifier free guidance, convolution 기반의 VAE, transformer 기반 DDPM을 사용한다__"],"metadata":{"id":"dEqihlrNWRzv"}},{"cell_type":"markdown","source":["## 3. Diffusion Transformer Design Space"],"metadata":{"id":"l2_HRnyKWRxm"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=10HmVQYk1nqzO0oDFR8a4O1k1FIklZqyk\">"],"metadata":{"id":"Nxu-bOY_nuo9"}},{"cell_type":"markdown","source":["### Patchify\n","ViT의 patchify방식을 사용하였다.  \n","각각의 patch size는 $p \\times p \\times C$이다."],"metadata":{"id":"YSIwyMlWWRtn"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1_nCHqnKk-r51QRwDJJx6iEeWug-D4QVA\" height=300>"],"metadata":{"id":"SPcMxUxjWRrG"}},{"cell_type":"markdown","source":["patchify이후, 모든 input token들에 ViT와 마찬가지로 frequency-based positional embedding을 사용.(sine-cosine)"],"metadata":{"id":"z657SZG0WRod"}},{"cell_type":"markdown","source":["p값에 따라서 inuput sequence 길이가 정해지는데, 이는 모델의 파라미터 수에는 큰 영향을 주지 않고, Gflops(계산 수)에는 상당한 영향을 미친다.($n^2$)  \n","\n","p 값을 2, 4, 8로 적용해보았다."],"metadata":{"id":"jmVAWebMWRhC"}},{"cell_type":"markdown","source":["### DiT block design"],"metadata":{"id":"EsYiGphGKZag"}},{"cell_type":"markdown","source":["diffusion 모델에서 condition 정보(t : time step, c : class labels 등)를 넣는 것은 중요하다. 여러 방법으로 디자인해보았다."],"metadata":{"id":"qlhK-SbgpAch"}},{"cell_type":"markdown","source":["+ In-context conditioning  \n","    ViT에서 cls token과 비슷하게, input sequence에 두개의 추가 token으로 embedding한다.  \n","    마지막 output에서 해당 token들을 제거한다."],"metadata":{"id":"GQdrGggnpAZ4"}},{"cell_type":"markdown","source":["+ Cross-attention block  \n","    embedding한 t, c를 길이 2짜리의 sequence로 concate해놓고 이번엔 image token과 cross-attention을 해준다."],"metadata":{"id":"OlGznVd0pALe"}},{"cell_type":"markdown","source":["+ Adaptive layer norm (adaLN) block  \n","    layer norm 이후에 t,c token을 통해 scale & shift 해준다. 이 때 regress 모델을 통해 해당 factor를 예측시킨다."],"metadata":{"id":"_bwl08oOpAJk"}},{"cell_type":"markdown","source":["+ adaLN-Zero block  \n","    + 기존 연구에서 residual block의 경우 마지막 conv block에 대해서 zero-initializing이 학습을 가속화 해준다는 연구가 있다.  \n","    + 이와 마찬가지로 모든 DiT block의 residual connection 이전에 dimension-wise scaling 파라미터를 적용하였다. 그리고,  MLP를 통과하고 나온 해당 파라미터가 zero-vector가 되도록 initialize하였다."],"metadata":{"id":"jvlthubCpAHd"}},{"cell_type":"markdown","source":["__즉, $\\textrm{MLP}(\\textrm{embed}(t, c)) = \\vec\\gamma, \\vec\\beta, \\vec\\alpha$ 이고,\n","$\\alpha$는 0이 되도록 초기화__  \n","그리고 이 때의 block은 Gflops상 무시할만한 크기이다."],"metadata":{"id":"Sw8c4b_FpAFN"}},{"cell_type":"markdown","source":["### Model size\n"],"metadata":{"id":"3Gw3Yg6upABT"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1qeghfPbBKzVPLjFFKLMQT-g53VXl_UPT\" height=200>"],"metadata":{"id":"sn9rqhVDo_-Q"}},{"cell_type":"markdown","source":["ViT에서와 마찬가지로 scaling하기 위해 N, d, h를 사용하였다. 이에 따라 Gflops가 변화하였다."],"metadata":{"id":"gCn3DvDgo_7g"}},{"cell_type":"markdown","source":["모델 사이즈에 따라서 0.3 ~ 118.3까지의 변화가 있었다."],"metadata":{"id":"WfILBgXVo_5F"}},{"cell_type":"markdown","source":["### Transformer decoder"],"metadata":{"id":"TeGvsvW6xuiI"}},{"cell_type":"markdown","source":["layer norm하고 각 token에 대해서 $p\\times p\\times2C$로 linearly decoding을 해준다."],"metadata":{"id":"X-w3FOQExugb"}},{"cell_type":"markdown","source":["그리고, 해당 output을 각각 원래 image위치로 재배열하고 noise와 covariance($\\epsilon, \\Sigma$)를 예측하는데에 사용한다."],"metadata":{"id":"AkZKflbIxueu"}},{"cell_type":"markdown","source":["## 4. Experimental Setup"],"metadata":{"id":"h2mIj77Jxucw"}},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"DQ_J_NgkmhF4"}},{"cell_type":"markdown","source":["+ Diffusion setup\n","    + ADM(Diffusion model beats GANs)에서 사용한 training setting을 그대로 사용하였다.  \n","    + VAE는 Stable Diffusion을 그대로 사용하였다."],"metadata":{"id":"tthqizJ4_OW2"}},{"cell_type":"markdown","source":["+ DiT setup\n","    + DiT모델을 training 할 때에는 보통 ViT할 때와 달리 warmup scaduler, regularization을 딱히 사용하지 않아도 안정적이어서 그렇게 했다고한다.  \n","    + 훈련간에 model weight에대해 EMA를 적용하였다고 한다."],"metadata":{"id":"v0T55t20_OTz"}},{"cell_type":"markdown","source":["### Evaluation\n","FID-50k를 주요 지표로 삼았다.  \n","이외에도 sFID, IS, Precision/Recall에 대해서도 실험하였다"],"metadata":{"id":"BJbwgA5G_ORO"}},{"cell_type":"markdown","source":["## 5. Expriments"],"metadata":{"id":"lYfJQtFp_ON6"}},{"cell_type":"markdown","source":["### DiT block design / Scaling model and patch size"],"metadata":{"id":"EjiejwC6xuaj"}},{"cell_type":"markdown","source":["+ adaLN-Zero block이 다른 것들에 비해 낮은 compute로 좋은 FID score를 기록하였다. 앞으로 이 블럭을 사용한다.\n","+ model configs : S, B, L, XL\n","+ patch sizes : 8, 4, 2\n","\n","총 12개의 모델을 통해 분석해본다."],"metadata":{"id":"eS9dv01fxuXa"}},{"cell_type":"markdown","source":["### DiT Gflops are critical to improving performance"],"metadata":{"id":"PdfCDmMQxuTK"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1qYe9d8OGYVSkyN7-zoIGZm-gX1KYPTye\" height=300>"],"metadata":{"id":"1HND8FFDxuPP"}},{"cell_type":"markdown","source":["+ model과 patch 사이즈를 적절히 변경했을 때 Gflops와 FID점수가 명확히 log scale의 상관관계를 가진다.  \n","+ S/2와 B/4모델을 보면 각각의 파라미터 수는 다른데도 patch크기로 인해 동일한 Gflops를 갖게 되었고 FID점수 역시 동일하였다.  \n"],"metadata":{"id":"d_U5EAc2xuM2"}},{"cell_type":"markdown","source":["이러한 경향성은 이후에 다른 실험에서도 동일하게 나타난다."],"metadata":{"id":"ST8JlvJsxuKO"}},{"cell_type":"markdown","source":["### Larger DiT models are more compute-efficient"],"metadata":{"id":"boUHmISfxuFg"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1Yftdg7Vmu3XqZlcxHOAB1FYWg7F8ei7i\" height=350>"],"metadata":{"id":"8PNvynhJqP_0"}},{"cell_type":"markdown","source":["Training Compute = Gflops x batch size x training steps x 3"],"metadata":{"id":"zzXAFDtmwPl4"}},{"cell_type":"markdown","source":["+ 결국엔 compute efficiency면에서 작은 model을 long step training하더라도 더 큰 model의 적은 step에 비해 별로다.\n","+ patch가 크면, 적은 Gflops로도 더 좋은 성능을 보이는 경향을 보인다. 하지만, 일정 step이 넘어가면 결국 더 작은 patch일 때가 좋다."],"metadata":{"id":"_aVScXR8qP9H"}},{"cell_type":"markdown","source":["### Visualizing scaling"],"metadata":{"id":"UTyZqHpiqP5_"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1kVCY-_9M4y6EJ8GPJHvcNSNPSoPBJBcW\" height=400>"],"metadata":{"id":"m1Si0xRYqPBh"}},{"cell_type":"markdown","source":["### SOTA Diffusion\n","<img src=\"https://drive.google.com/uc?id=15xSjydrBTwo6yKFmcC-YxoXo0DO-SFDz\" height=350>\n","<img src=\"https://drive.google.com/uc?id=1yWStRlIr7z-dKrcZACE7A8SK2s3osKyI\" height=250>"],"metadata":{"id":"RogylIjNqO_g"}},{"cell_type":"markdown","source":["256 size에서는 모든 생성모델에 대해 SOTA,   \n","512 size에서는 Diffusion 모델중에서 SOTA"],"metadata":{"id":"x6cDPnykqO9w"}},{"cell_type":"markdown","source":["### Scaling Model vs Sampling Compute"],"metadata":{"id":"w2Xu9o_aqO73"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1K8tVXKj6WJPBBtPnHxnd9tFVcfEzeSwp\" height=350>"],"metadata":{"id":"K4PZQP8sqO51"}},{"cell_type":"markdown","source":["각 모델에 대해서 [16, 32, 64, 128, 256, 1000]으로 sampling steps를 바꿔가며 FID를 측정해보았다."],"metadata":{"id":"X4mxsNC3qO3r"}},{"cell_type":"markdown","source":["+ L/2(1000 steps)와 XL/2(128 steps)를 비교해보았을 때, 비슷한 퀄리티에비해 연산량은 5배정도 차이가 난다.\n","+ 즉, sampling step이 model scaling에 비해 큰 영향을 미치지는 않는다."],"metadata":{"id":"maozU8TKqO0O"}},{"cell_type":"markdown","source":["## 결론"],"metadata":{"id":"r5oXWhLoyBqn"}},{"cell_type":"markdown","source":["Model backbone을 U-Net에서 Transformer 으로 바꾸어 scale관점에서 체계적으로 연구한 의의가있다."],"metadata":{"id":"HHJOy78oyEp7"}}]}